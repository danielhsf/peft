{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_NHUSifnII4"
      },
      "source": [
        "# Introdução\n",
        "\n",
        "Esse notebook introduz um guia inicial para uso da biblioteca PEFT para realizar o finetuning do modelo M2M100. Para esse exemplo, demonstro como posso usar um modelo de tradução genérico para adicionar camadas de pesos treinaveis para criar um modelo adaptado ao dominio de software"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx07AvYLK1LK"
      },
      "source": [
        "## Instalando bibliotecas\n",
        "\n",
        "Importe a biblioteca de requirements.txt no [repositorio no github](https://github.com/danielhsf/peft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWS5sPPDKpKM",
        "outputId": "10ef26b7-6c5b-463c-f904-3d99c15a168d"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXRitLKMsGhJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMYE5uwkK55Z"
      },
      "source": [
        "## Logando no Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo6ktJwLKwEn",
        "outputId": "296ad290-1abf-4b00-adfe-7f952456d423"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z_INzijK-lW"
      },
      "source": [
        "## Importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n1C9M9qKz8b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrp8gjRaLGd_"
      },
      "source": [
        "## Configuração base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5roRJnW_LDmF"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"facebook/m2m100_418M\"\n",
        "DATASET_NAME = \"kde4\"\n",
        "SOURCE_LANG = \"en\"\n",
        "TARGET_LANG = \"pt_BR\"\n",
        "SOURCE_LANG_M2M = \"en\" # M2M100 usa 'en' para Inglês\n",
        "TARGET_LANG_M2M = \"pt\" # M2M100 usa 'pt' para Português"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwm7u6wQLnQv"
      },
      "source": [
        "## Configurando o LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrzdDKB3LR5_"
      },
      "outputs": [],
      "source": [
        "# LoRA Configuration\n",
        "LORA_R = 16 # Rank\n",
        "LORA_ALPHA = 32 # Alpha\n",
        "LORA_DROPOUT = 0.05\n",
        "# M2M100 specific target modules. Inspect model.named_modules() to be sure.\n",
        "# Common ones are 'q_proj', 'k_proj', 'v_proj', 'out_proj' for attention layers.\n",
        "# For M2M100, encoder and decoder attention layers are named `encoder_attn` and `self_attn`\n",
        "# and their projections are `k_proj`, `v_proj`, `q_proj`, `out_proj`.\n",
        "# Let's target query and value projections in all attention blocks.\n",
        "LORA_TARGET_MODULES = [\n",
        "    \"q_proj\",\n",
        "    \"v_proj\",\n",
        "    # You can add \"k_proj\", \"out_proj\" if resources allow and you want to experiment\n",
        "    # \"fc1\", \"fc2\" # for FFN layers, less common for LoRA in NMT but possible\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2YY8ox2Ly4n"
      },
      "source": [
        "## Argumentos para treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKnCtdFzLvEM"
      },
      "outputs": [],
      "source": [
        "# Training Arguments\n",
        "OUTPUT_DIR = f\"./results_m2m100_lora_kde4_{SOURCE_LANG}_{TARGET_LANG}\"\n",
        "BATCH_SIZE = 4 # Adjust based on your GPU memory\n",
        "NUM_TRAIN_EPOCHS = 1 # Adjust as needed\n",
        "LEARNING_RATE = 2e-4 # Higher learning rate is common for LoRA\n",
        "WEIGHT_DECAY = 0.01\n",
        "LOGGING_STEPS = 50\n",
        "EVAL_STEPS = 200\n",
        "SAVE_STEPS = 200\n",
        "MAX_SOURCE_LENGTH = 128 # Max length for source sentences\n",
        "MAX_TARGET_LENGTH = 128 # Max length for target sentences\n",
        "FP16 = torch.cuda.is_available() # Use FP16 if a GPU is available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqSl-S_wL6In"
      },
      "source": [
        "## Argumento de reproducibilidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3sRAp0QL2Zg"
      },
      "outputs": [],
      "source": [
        "# For reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-uzeNOJMB1d"
      },
      "source": [
        "## Carregando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSaIcByKL8VF",
        "outputId": "79ef60c4-f906-4535-9ee3-0a0ffe2083f1"
      },
      "outputs": [],
      "source": [
        "# --- 1. Load Dataset ---\n",
        "print(\"Loading dataset...\")\n",
        "try:\n",
        "    # The KDE4 dataset on Hugging Face Hub is structured as language pairs\n",
        "    dataset = load_dataset(DATASET_NAME, lang1=SOURCE_LANG, lang2=TARGET_LANG)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    print(\"Please ensure you have an internet connection and the dataset name/parameters are correct.\")\n",
        "    exit()\n",
        "\n",
        "# For demonstration, let's use a smaller subset. Remove/adjust for full training.\n",
        "# Using 'train' split as it's usually the largest.\n",
        "if 'train' not in dataset:\n",
        "    print(f\"Error: 'train' split not found in dataset. Available splits: {list(dataset.keys())}\")\n",
        "    exit()\n",
        "\n",
        "# Split the train dataset into train and validation\n",
        "# KDE4 might not have a predefined validation split for the lang pair\n",
        "train_test_split = dataset['train'].train_test_split(test_size=0.1, seed=SEED)\n",
        "\n",
        "processed_dataset = DatasetDict({\n",
        "    'train': train_test_split['train'].select(range(min(2000, len(train_test_split['train'])))), # Use 2000 samples for training\n",
        "    'validation': train_test_split['test'].select(range(min(200, len(train_test_split['test']))))   # Use 200 samples for validation\n",
        "})\n",
        "\n",
        "'''\n",
        "processed_dataset = DatasetDict({\n",
        "    'train': train_test_split['train'],\n",
        "    'validation': train_test_split['test']\n",
        "})\n",
        "'''\n",
        "\n",
        "print(f\"Dataset loaded and split. Train size: {len(processed_dataset['train'])}, Validation size: {len(processed_dataset['validation'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cXDtwxQOtTY"
      },
      "source": [
        "## Carregando Tokenizer e Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "82c1946560a34b099246572ca4bd2317",
            "cc45b6aa7123470f87190a85af0cc589",
            "ebc3a8f4ff3b4d639704596d63786664",
            "5c60b1b6009c499a90d116492134f9c6",
            "a3e2dcb985704edab48310c0f0710b25",
            "24e90f39a89b4d5dac387f30669d59b9",
            "43239499c0854f9a82480944a797df4a",
            "1d90b16f6bc44aa8b15958d85eabfb9a",
            "e4d335b1c31d406dbeca570c7e88e6da",
            "ccedcf85f6b849c0b862b95b25a60098",
            "5b6b9642f8534dfab31b71b80258e011"
          ]
        },
        "id": "gAeMal2GOvSL",
        "outputId": "4631e31f-b716-4e7f-a860-cba7be77ed34"
      },
      "outputs": [],
      "source": [
        "# --- 2. Load Tokenizer and Model ---\n",
        "print(\"Loading tokenizer and model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=SOURCE_LANG_M2M, tgt_lang=TARGET_LANG_M2M)\n",
        "# Load the base model first\n",
        "base_model_for_lora = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcmFxQVVNQ-P"
      },
      "source": [
        "## Preprocesamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qOo4O86NT2A"
      },
      "outputs": [],
      "source": [
        "# --- 3. Preprocessing Function ---\n",
        "def preprocess_function(examples):\n",
        "    if not examples.get('translation'):\n",
        "        print(\"Warning: 'translation' key not found in examples. Skipping this batch.\")\n",
        "        return {'input_ids': [], 'attention_mask': [], 'labels': []}\n",
        "\n",
        "    inputs = [ex[SOURCE_LANG] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[TARGET_LANG] for ex in examples[\"translation\"]]\n",
        "\n",
        "    # Set source language for tokenizer\n",
        "    tokenizer.src_lang = SOURCE_LANG_M2M\n",
        "    model_inputs = tokenizer(inputs, max_length=MAX_SOURCE_LENGTH, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Set target language for tokenizer\n",
        "    tokenizer.tgt_lang = TARGET_LANG_M2M\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=MAX_TARGET_LENGTH, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    # Replace padding token id in labels with -100 to be ignored by loss function\n",
        "    for i in range(len(model_inputs[\"labels\"])):\n",
        "        model_inputs[\"labels\"][i] = [\n",
        "            (l if l != tokenizer.pad_token_id else -100) for l in model_inputs[\"labels\"][i]\n",
        "        ]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "af43a90fbe9a40d59b95c5b499f4d9f9",
            "47b5739ab01d47699a6e3d0dc87494ef",
            "1e8675a6dcc8409e8e85c3834583756e",
            "5dd5f013b6c341348bce8aaf3b71763d",
            "652b4136d7a644dcb52989142974b5c6",
            "46c35d53ce8d4a1db3d8e5a8eb698988",
            "ef6b4412061b41888525c54d6f5f1f46",
            "b7beb0b6f2984c50ad56b9447bed8bec",
            "22ea1051db164e9db8c9b4566ff2db1e",
            "3119d9e69a964f8c9d1bdf355bc9e32c",
            "db8e40d446c846ff903ea7daf4c87c07",
            "849364f9115947239feb0cd9ed0f77a5",
            "4c3a56244c474bf6a58d679fef5091c1",
            "69c5a9bc91c242c4ac87bffd3aea4a78",
            "127952176e274333a8180f99a9a2b1d7",
            "2f53581a5a2444389fde6ce351cd640e",
            "3adcba5245af4da8bbb9b8869b059ab3",
            "c20ea40d112c476bbb36ff6de7f2a581",
            "49a6b5d349d349c1960159d5da9ec03f",
            "62895ee3444945a2a61b1008e540419b",
            "0836005bb9314991a33989b22c43fbfd",
            "03cbc8c8caff477cb4434635945585a5"
          ]
        },
        "id": "Mz_h0c2dNWSY",
        "outputId": "74a60e0c-932b-461a-b88f-e6899b67a7dc"
      },
      "outputs": [],
      "source": [
        "print(\"Preprocessing dataset...\")\n",
        "tokenized_datasets = processed_dataset.map(preprocess_function, batched=True, remove_columns=processed_dataset[\"train\"].column_names)\n",
        "print(\"Dataset preprocessed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ02Q8cvNXLi"
      },
      "source": [
        "## Configurando LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSZvth4ljIhC",
        "outputId": "3860162e-58cc-48cc-a1be-c5011c5ef5e6"
      },
      "outputs": [],
      "source": [
        "# --- 4. Configure LoRA ---\n",
        "print(\"Configuring LoRA...\")\n",
        "lora_config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=LORA_TARGET_MODULES,\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "\n",
        "# model = prepare_model_for_kbit_training(base_model_for_lora) # If using k-bit training\n",
        "# model = get_peft_model(model, lora_config) # If using k-bit training\n",
        "model = get_peft_model(base_model_for_lora, lora_config) # Apply LoRA to the base model\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWLNeFavjI6C"
      },
      "source": [
        "## Setando argumentos de treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHiOBGWvMDmf",
        "outputId": "8dd7f390-6ac5-4994-9e8a-58f58dcc7b87"
      },
      "outputs": [],
      "source": [
        "# --- 5. Training Arguments and Trainer ---\n",
        "print(\"Setting up training arguments and trainer...\")\n",
        "forced_bos_token_id = tokenizer.lang_code_to_id[TARGET_LANG_M2M]\n",
        "\n",
        "# ---- MODIFICATION START ----\n",
        "# Get the model's existing generation_config (it's an object, not a dict)\n",
        "# For PEFT models, model.generation_config should access the base model's config.\n",
        "generation_config = model.generation_config\n",
        "# Update it with the forced_bos_token_id\n",
        "generation_config.forced_bos_token_id = forced_bos_token_id\n",
        "# You can also set other generation parameters here if you want them to be part of this base config\n",
        "# generation_config.max_length = MAX_TARGET_LENGTH # This will be overridden by Seq2SeqTrainingArguments if set there\n",
        "# generation_config.num_beams = 4 # This will be overridden by Seq2SeqTrainingArguments if set there\n",
        "# ---- MODIFICATION END ----\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=MAX_TARGET_LENGTH, # Trainer will use this to update its copy of generation_config\n",
        "    generation_num_beams=4,                  # Trainer will use this to update its copy of generation_config\n",
        "    fp16=FP16,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=EVAL_STEPS,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=SAVE_STEPS,\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"tensorboard\",\n",
        "    # ---- MODIFICATION FOR generation_config ----\n",
        "    generation_config=generation_config, # Pass the GenerationConfig object\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=f\"danhsf/m2m100-lora-kde4-1epoch-{SOURCE_LANG}-{TARGET_LANG}\",\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    pad_to_multiple_of=8 if FP16 else None\n",
        ")\n",
        "\n",
        "# Optional: Compute Metrics (e.g., BLEU)\n",
        "# You would need to install sacrebleu: pip install sacrebleu\n",
        "import numpy as np\n",
        "import sacrebleu\n",
        "def compute_metrics(eval_preds):\n",
        "     preds, labels = eval_preds\n",
        "     if isinstance(preds, tuple):\n",
        "         preds = preds[0]\n",
        "\n",
        "     # Replace -100 in the labels as we can't decode them.\n",
        "     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "#     # SacreBLEU expects a list of reference strings for each prediction\n",
        "     decoded_labels_sacrebleu = [[label] for label in decoded_labels]\n",
        "\n",
        "     result = sacrebleu.corpus_bleu(decoded_preds, decoded_labels_sacrebleu)\n",
        "     return {\"bleu\": result.score}\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics, # Uncomment if using compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILB36XrbjW1F"
      },
      "source": [
        "## Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "uX1KYz5IO27W",
        "outputId": "b30f4bb4-c736-40f0-eb1c-8c98ff7b9eb3"
      },
      "outputs": [],
      "source": [
        "# --- 6. Train ---\n",
        "print(\"Starting training...\")\n",
        "try:\n",
        "    trainer.train()\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    if \"CUDA out of memory\" in str(e):\n",
        "        print(\"CUDA out of memory. Try reducing BATCH_SIZE, MAX_SOURCE_LENGTH, MAX_TARGET_LENGTH, or LORA_R.\")\n",
        "        print(\"Using gradient_accumulation_steps in TrainingArguments can also help.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# --- 7. Save LoRA Adapter ---\n",
        "print(\"Saving LoRA adapter...\")\n",
        "lora_adapter_path = os.path.join(OUTPUT_DIR, \"final_lora_adapter\")\n",
        "model.save_pretrained(lora_adapter_path)\n",
        "tokenizer.save_pretrained(lora_adapter_path) # Save tokenizer with adapter for convenience\n",
        "print(f\"LoRA adapter saved to {lora_adapter_path}\")\n",
        "\n",
        "# --- 8. Inference Example (Optional) ---\n",
        "print(\"\\n--- Inference Example ---\")\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load the base model\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "# Load the LoRA adapter\n",
        "loaded_model = PeftModel.from_pretrained(base_model, lora_adapter_path)\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(lora_adapter_path) # Uses the saved tokenizer\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = loaded_model.to(device)\n",
        "loaded_model.eval() # Set to evaluation mode\n",
        "\n",
        "test_sentence_en = \"The user can click the button to save the file.\"\n",
        "print(f\"Source ({SOURCE_LANG}): {test_sentence_en}\")\n",
        "\n",
        "# Tokenize for M2M100\n",
        "loaded_tokenizer.src_lang = SOURCE_LANG_M2M # Set source language\n",
        "inputs = loaded_tokenizer(test_sentence_en, return_tensors=\"pt\", truncation=True, max_length=MAX_SOURCE_LENGTH).to(device)\n",
        "\n",
        "# Generate translation\n",
        "# M2M100 requires forced_bos_token_id to specify the target language for generation\n",
        "generated_tokens = loaded_model.generate(\n",
        "    **inputs,\n",
        "    forced_bos_token_id=loaded_tokenizer.lang_code_to_id[TARGET_LANG_M2M],\n",
        "    max_length=MAX_TARGET_LENGTH,\n",
        "    num_beams=5, # Use beam search for better quality\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Decode the generated tokens\n",
        "translation_fr = loaded_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "print(f\"Translated ({TARGET_LANG}): {translation_fr}\")\n",
        "\n",
        "print(\"\\n--- Example with original M2M100 (for comparison) ---\")\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=SOURCE_LANG_M2M, tgt_lang=TARGET_LANG_M2M)\n",
        "\n",
        "original_inputs = original_tokenizer(test_sentence_en, return_tensors=\"pt\").to(device)\n",
        "original_generated_tokens = original_model.generate(\n",
        "    **original_inputs,\n",
        "    forced_bos_token_id=original_tokenizer.lang_code_to_id[TARGET_LANG_M2M],\n",
        "    max_length=MAX_TARGET_LENGTH\n",
        ")\n",
        "original_translation_fr = original_tokenizer.batch_decode(original_generated_tokens, skip_special_tokens=True)[0]\n",
        "print(f\"Original M2M100 Translated ({TARGET_LANG}): {original_translation_fr}\")\n",
        "\n",
        "print(\"\\nScript finished successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpmxdlaulsr-",
        "outputId": "c8da52a7-3042-411a-c1f2-9a59b718e073"
      },
      "outputs": [],
      "source": [
        "# --- 8. Inference Example (Optional) ---\n",
        "print(\"\\n--- Inference Example ---\")\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load the base model\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "# Load the LoRA adapter\n",
        "loaded_model = PeftModel.from_pretrained(base_model, lora_adapter_path)\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(lora_adapter_path) # Uses the saved tokenizer\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model = loaded_model.to(device)\n",
        "loaded_model.eval() # Set to evaluation mode\n",
        "\n",
        "test_sentence_en = \"home\"\n",
        "print(f\"Source ({SOURCE_LANG}): {test_sentence_en}\")\n",
        "\n",
        "# Tokenize for M2M100\n",
        "loaded_tokenizer.src_lang = SOURCE_LANG_M2M # Set source language\n",
        "inputs = loaded_tokenizer(test_sentence_en, return_tensors=\"pt\", truncation=True, max_length=MAX_SOURCE_LENGTH).to(device)\n",
        "\n",
        "# Generate translation\n",
        "# M2M100 requires forced_bos_token_id to specify the target language for generation\n",
        "generated_tokens = loaded_model.generate(\n",
        "    **inputs,\n",
        "    forced_bos_token_id=loaded_tokenizer.lang_code_to_id[TARGET_LANG_M2M],\n",
        "    max_length=MAX_TARGET_LENGTH,\n",
        "    num_beams=5, # Use beam search for better quality\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Decode the generated tokens\n",
        "translation_fr = loaded_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "print(f\"Translated ({TARGET_LANG}): {translation_fr}\")\n",
        "\n",
        "print(\"\\n--- Example with original M2M100 (for comparison) ---\")\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=SOURCE_LANG_M2M, tgt_lang=TARGET_LANG_M2M)\n",
        "\n",
        "original_inputs = original_tokenizer(test_sentence_en, return_tensors=\"pt\").to(device)\n",
        "original_generated_tokens = original_model.generate(\n",
        "    **original_inputs,\n",
        "    forced_bos_token_id=original_tokenizer.lang_code_to_id[TARGET_LANG_M2M],\n",
        "    max_length=MAX_TARGET_LENGTH\n",
        ")\n",
        "original_translation_fr = original_tokenizer.batch_decode(original_generated_tokens, skip_special_tokens=True)[0]\n",
        "print(f\"Original M2M100 Translated ({TARGET_LANG}): {original_translation_fr}\")\n",
        "\n",
        "print(\"\\nScript finished successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXzLYYD4nIqb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03cbc8c8caff477cb4434635945585a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0836005bb9314991a33989b22c43fbfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127952176e274333a8180f99a9a2b1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0836005bb9314991a33989b22c43fbfd",
            "placeholder": "​",
            "style": "IPY_MODEL_03cbc8c8caff477cb4434635945585a5",
            "value": " 200/200 [00:00&lt;00:00, 939.18 examples/s]"
          }
        },
        "1d90b16f6bc44aa8b15958d85eabfb9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8675a6dcc8409e8e85c3834583756e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7beb0b6f2984c50ad56b9447bed8bec",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22ea1051db164e9db8c9b4566ff2db1e",
            "value": 2000
          }
        },
        "22ea1051db164e9db8c9b4566ff2db1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24e90f39a89b4d5dac387f30669d59b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f53581a5a2444389fde6ce351cd640e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3119d9e69a964f8c9d1bdf355bc9e32c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3adcba5245af4da8bbb9b8869b059ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43239499c0854f9a82480944a797df4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46c35d53ce8d4a1db3d8e5a8eb698988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b5739ab01d47699a6e3d0dc87494ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c35d53ce8d4a1db3d8e5a8eb698988",
            "placeholder": "​",
            "style": "IPY_MODEL_ef6b4412061b41888525c54d6f5f1f46",
            "value": "Map: 100%"
          }
        },
        "49a6b5d349d349c1960159d5da9ec03f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3a56244c474bf6a58d679fef5091c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3adcba5245af4da8bbb9b8869b059ab3",
            "placeholder": "​",
            "style": "IPY_MODEL_c20ea40d112c476bbb36ff6de7f2a581",
            "value": "Map: 100%"
          }
        },
        "5b6b9642f8534dfab31b71b80258e011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c60b1b6009c499a90d116492134f9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccedcf85f6b849c0b862b95b25a60098",
            "placeholder": "​",
            "style": "IPY_MODEL_5b6b9642f8534dfab31b71b80258e011",
            "value": " 1.94G/1.94G [00:06&lt;00:00, 379MB/s]"
          }
        },
        "5dd5f013b6c341348bce8aaf3b71763d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3119d9e69a964f8c9d1bdf355bc9e32c",
            "placeholder": "​",
            "style": "IPY_MODEL_db8e40d446c846ff903ea7daf4c87c07",
            "value": " 2000/2000 [00:02&lt;00:00, 883.91 examples/s]"
          }
        },
        "62895ee3444945a2a61b1008e540419b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "652b4136d7a644dcb52989142974b5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c5a9bc91c242c4ac87bffd3aea4a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a6b5d349d349c1960159d5da9ec03f",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62895ee3444945a2a61b1008e540419b",
            "value": 200
          }
        },
        "82c1946560a34b099246572ca4bd2317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc45b6aa7123470f87190a85af0cc589",
              "IPY_MODEL_ebc3a8f4ff3b4d639704596d63786664",
              "IPY_MODEL_5c60b1b6009c499a90d116492134f9c6"
            ],
            "layout": "IPY_MODEL_a3e2dcb985704edab48310c0f0710b25"
          }
        },
        "849364f9115947239feb0cd9ed0f77a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c3a56244c474bf6a58d679fef5091c1",
              "IPY_MODEL_69c5a9bc91c242c4ac87bffd3aea4a78",
              "IPY_MODEL_127952176e274333a8180f99a9a2b1d7"
            ],
            "layout": "IPY_MODEL_2f53581a5a2444389fde6ce351cd640e"
          }
        },
        "a3e2dcb985704edab48310c0f0710b25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af43a90fbe9a40d59b95c5b499f4d9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47b5739ab01d47699a6e3d0dc87494ef",
              "IPY_MODEL_1e8675a6dcc8409e8e85c3834583756e",
              "IPY_MODEL_5dd5f013b6c341348bce8aaf3b71763d"
            ],
            "layout": "IPY_MODEL_652b4136d7a644dcb52989142974b5c6"
          }
        },
        "b7beb0b6f2984c50ad56b9447bed8bec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20ea40d112c476bbb36ff6de7f2a581": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc45b6aa7123470f87190a85af0cc589": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e90f39a89b4d5dac387f30669d59b9",
            "placeholder": "​",
            "style": "IPY_MODEL_43239499c0854f9a82480944a797df4a",
            "value": "model.safetensors: 100%"
          }
        },
        "ccedcf85f6b849c0b862b95b25a60098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8e40d446c846ff903ea7daf4c87c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d335b1c31d406dbeca570c7e88e6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebc3a8f4ff3b4d639704596d63786664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d90b16f6bc44aa8b15958d85eabfb9a",
            "max": 1935682568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4d335b1c31d406dbeca570c7e88e6da",
            "value": 1935682568
          }
        },
        "ef6b4412061b41888525c54d6f5f1f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
